{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate loss\n",
    "def evaluate_loss(X_test_scaled, y_test_scaled, model):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "    print(f'Mean Squared Error on Test Set: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset\n",
    "train_dataset = pd.read_excel('/home/framework/coding_python/wqi_ann/src/data_input/train_dataset.xlsx')  # replace with the path to your excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features (11 variables) and target (WQI)\n",
    "x = train_dataset[['ph', 'Total  Hardness', 'Total Alkalinity', 'Cl', 'NO3', 'SO4', 'F', 'TDS', 'Fe', 'As (ppb)', 'Pb (ppb)']]\n",
    "y = train_dataset[['WQI']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the features and target using MinMaxScaler\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(x)\n",
    "y_scaled = scaler_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an XGBoost model with more customizable parameters\n",
    "model = XGBRegressor(n_estimators=300,      # Number of boosting rounds\n",
    "                     learning_rate=0.05,    # Step size shrinkage\n",
    "                     max_depth=6,           # Depth of each tree\n",
    "                     subsample=0.8,         # Fraction of samples used for training each tree\n",
    "                     colsample_bytree=0.8,  # Fraction of features used per tree\n",
    "                     reg_alpha=0.1,         # L1 regularization term\n",
    "                     reg_lambda=0.5,        # L2 regularization term\n",
    "                     random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset (11 variables without WQI)\n",
    "test_dataset = pd.read_excel('/home/framework/coding_python/wqi_ann/src/data_input/test_dataset.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the 11 variables\n",
    "X_test_data = test_dataset[['pH', 'Total Hardness', 'Total Alkalinity', 'Cl', 'NO3', 'SO4', 'F', 'TDS', 'Fe', 'As (ppb)', 'Pb (ppb)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the test data using the same scaler fitted to the training data\n",
    "X_test_data_scaled = scaler_X.transform(X_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict WQI values using the trained model\n",
    "predicted_wqi_scaled = model.predict(X_test_data_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print scaled prediction using the trained model\n",
    "print(\"Scaled prediction:\", predicted_wqi_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform to get the original WQI values\n",
    "predicted_wqi = scaler_y.inverse_transform(predicted_wqi_scaled.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unscaled prediction for debugging\n",
    "print(\"Unscaled predictions:\", predicted_wqi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loss of the model on the test set\n",
    "evaluate_loss(X_test, y_test, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predicted WQI values to the test dataset\n",
    "test_dataset['WQI'] = predicted_wqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated test dataset to a new Excel file\n",
    "output_excel_path = '/home/framework/coding_python/wqi_ann/src/data_output/validation_dataset_output.xlsx'\n",
    "test_dataset.to_excel(output_excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WQI values have been added and saved to the output Excel file.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
