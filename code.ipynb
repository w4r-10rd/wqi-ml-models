{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate loss\n",
    "def evaluate_loss(X_test_scaled, y_test_scaled, model):\n",
    "    loss = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "    print(f'Mean Squared Error on Test Set: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset\n",
    "train_dataset = pd.read_excel('/home/framework/coding_python/wqi_ann/src/data_input/train_dataset.xlsx') # replace with the path to your excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first  10 values of the training dataset\n",
    "train_dataset.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features (11 variables) and targer (WQI)\n",
    "x = train_dataset[['ph', 'Total  Hardness', 'Total Alkalinity', 'Cl', 'NO3', 'SO4', 'F', 'TDS', 'Fe', 'As (ppb)', 'Pb (ppb)']]\n",
    "y = train_dataset[['WQI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the features and target using MinMaxScaler\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(x)\n",
    "y_scaled = scaler_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8, verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset (11 variables without WQI)\n",
    "test_dataset = pd.read_exel('/home/framework/coding_python/wqi_ann/src/data_input/test_dataset.xlsx')\n",
    "\n",
    "# extract the 11 variables\n",
    "X_test_data = test_dataset[['pH', 'Total Hardness', 'Total Alkalinity', 'Cl', 'NO3', 'SO4', 'F', 'TDS', 'Fe', 'As (ppb)', 'Pb (ppb)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the test data using the same scaler fited to the training data\n",
    "X_test_data_scaled = scaler_X.transform(X_test_data)\n",
    "\n",
    "# Predict WQI values using the trained model\n",
    "predicted_wqi_scaled = model.predict(X_test_data_scaled)\n",
    "\n",
    "#print scaled prediction using the trained model\n",
    "print(\"Scaled prediction:\" , predicted_wqi_scaled)\n",
    "\n",
    "# Inverse transform to get the original WQI values\n",
    "predicted_wqi = scaler_y.inverse_transform(predicted_wqi_scaled)\n",
    "\n",
    "#print unscaled prediction for debugging\n",
    "print(\"Unscaled predictions:\",predicted_wqi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loss of the model on the test set\n",
    "evaluate_loss(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predicted WQI values to the test dataset\n",
    "test_dataset['WQI'] = predicted_wqi\n",
    "\n",
    "# Save the updated test dataset to a new Excel file\n",
    "output_excel_path = '/home/framework/coding_python/wqi_ann/src/data_output/validation_dataset_output.xlsx'\n",
    "test_dataset.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(\"WQI values have been added and saved to the output Excel file.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
